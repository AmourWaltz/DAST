{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size:  800\n",
      "Data size for llama31: 800\n",
      "Processed data size for llama31: 747\n",
      "Data size for llama31_ins: 800\n",
      "Processed data size for llama31_ins: 747\n",
      "Data size for qwen25: 800\n",
      "Processed data size for qwen25: 747\n",
      "Data size for qwen25_ins: 800\n",
      "Processed data size for qwen25_ins: 747\n"
     ]
    }
   ],
   "source": [
    "# Remove the questions with pictures in TheoremQA dataset\n",
    "\n",
    "from utils import *\n",
    "\n",
    "models = [\"llama31\", \"llama31_ins\", \"qwen25\", \"qwen25_ins\"]\n",
    "\n",
    "ori_file = \"./../data/theorem/raw/test.json\"\n",
    "prep_file = \"./../exp/theorem/infer/{}_theorem_base_icl/test_generate.json\"\n",
    "temp_file = \"./../exp/theorem/infer/{}_theorem_base_icl/temp.json\"\n",
    "\n",
    "ori_data = read_json(ori_file)\n",
    "\n",
    "print(\"Data size: \", len(ori_data))\n",
    "\n",
    "for model in models:\n",
    "    inp_file = prep_file.format(model)\n",
    "    prep_data = read_json(inp_file)\n",
    "\n",
    "    print(\"Data size for {}: {}\".format(model, len(prep_data)))\n",
    "    prep_list = []\n",
    "    for idx, item in enumerate(ori_data):\n",
    "        if item[\"Picture\"] is False:\n",
    "            prep_list.append(prep_data[idx])\n",
    "\n",
    "    print(\"Processed data size for {}: {}\".format(model, len(prep_list)))\n",
    "    write_json(inp_file, prep_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size:  1496\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "\n",
    "ori_file = \"./../data/talscq/raw/test_v2.json\"\n",
    "out_file = \"./../data/talscq/raw/test.json\"\n",
    "\n",
    "ori_data = read_json(ori_file)\n",
    "\n",
    "print(\"Data size: \", len(ori_data))\n",
    "\n",
    "for idx, item in enumerate(ori_data):\n",
    "    item[\"answer\"] = item[\"answer\"].replace(\"$\", \"\").strip()\n",
    "\n",
    "write_json(out_file, ori_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size:  14973\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "\n",
    "inp_path_1 = \"./../data/gsm8k/raw/train.json\"\n",
    "inp_path_2 = \"./../data/math/raw/train.json\"\n",
    "out_path = \"./../data/id/raw/train.json\"\n",
    "\n",
    "json_merge([inp_path_1, inp_path_2], out_path)\n",
    "data_pool = read_json(out_path)\n",
    "print(\"Data size: \", len(data_pool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dast",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
