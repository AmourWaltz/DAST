{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "input_path = \"./../../data/triviaqa/sample.json\"\n",
    "data_path = \"./../../data/triviaqa/validation.json\"\n",
    "output_path = \"./../../data/triviaqa/sample_out.json\"\n",
    "\n",
    "with open(input_path, \"r\") as fr:\n",
    "    samples = json.load(fr)\n",
    "\n",
    "with open(data_path, \"r\") as fr:\n",
    "    data_pool = json.load(fr)\n",
    "\n",
    "sample_set = []\n",
    "for idx, sample in enumerate(samples):\n",
    "    new_sample = {}\n",
    "    assert sample[\"question\"] == data_pool[idx][\"question\"]\n",
    "    new_sample[\"question_id\"] = data_pool[idx][\"question_id\"]\n",
    "    new_sample.update(sample)\n",
    "    sample_set.append(new_sample)\n",
    "\n",
    "with open(output_path, \"w\") as fw:\n",
    "    json.dump(sample_set, fw, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "input_path = \"./../../data/triviaqa/sample.json\"\n",
    "\n",
    "utils.jsonl2json(input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1962\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "\n",
    "input_paths = [\"./../../data/triviaqa/sample_1.json\", \"./../../data/triviaqa/sample_2.json\"]\n",
    "output_path = \"./../../data/triviaqa/sample.json\"\n",
    "\n",
    "\n",
    "def json_merge(files, out_file):\n",
    "    data = []\n",
    "    for file in files:\n",
    "        data += utils.read_json(file)\n",
    "    utils.write_json(out_file, data)\n",
    "\n",
    "json_merge(input_paths, output_path)\n",
    "print(len(utils.read_json(output_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "654\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "\n",
    "input_paths = \"./../../data/triviaqa/sample_1962.json\"\n",
    "output_path = \"./../../data/triviaqa/sample.json\"\n",
    "\n",
    "data_pool = utils.read_json(input_paths)\n",
    "\n",
    "sample_set = []\n",
    "\n",
    "for data in data_pool[::3]:\n",
    "    sample_set.append(data)\n",
    "\n",
    "utils.write_json(output_path, sample_set)\n",
    "print(len(utils.read_json(output_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6042\n",
      "6042\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "\n",
    "input_paths = [\"./../../data/web_qa/me_validation.ann.json\", \"./../../data/web_qa/me_test.ann.json\"]\n",
    "output_path = \"./../../data/web_qa/validation.json\"\n",
    "\n",
    "data_pool = utils.read_jsons(input_paths)\n",
    "\n",
    "print(len(data_pool))\n",
    "samples_set = []\n",
    "\n",
    "for data in data_pool:\n",
    "    samples_set.append(data)\n",
    "\n",
    "utils.write_json(output_path, samples_set)\n",
    "print(len(utils.read_json(output_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19131\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "\n",
    "input_paths = \"./../../data/triviaqa/prep/llama3_triviaqa_train_sample_2w_1shot.json\"\n",
    "output_path = \"./../../data/triviaqa/prep/train_2w.json\"\n",
    "\n",
    "data_pool = utils.read_json(input_paths)\n",
    "\n",
    "sample_set = []\n",
    "\n",
    "for data in data_pool:\n",
    "    sample_set.append({\n",
    "        \"question_id\": data[\"question_id\"],\n",
    "        \"question\": data[\"question\"],\n",
    "        \"answer\": data[\"answer\"]\n",
    "    })\n",
    "\n",
    "utils.write_json(output_path, sample_set)\n",
    "print(len(utils.read_json(output_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './../../exp/triviaqa/infer/llama3_triviaqa_validation_sample_2k_1shot/generate2.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\n\u001b[1;32m      3\u001b[0m input_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./../../exp/triviaqa/infer/llama3_triviaqa_validation_sample_2k_1shot/generate2.json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 5\u001b[0m utils\u001b[38;5;241m.\u001b[39mjsonl2json(input_path, input_path)\n",
      "File \u001b[0;32m/workspace/project/refact/code/utils.py:106\u001b[0m, in \u001b[0;36mjsonl2json\u001b[0;34m(file1, file2)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mjsonl2json\u001b[39m(file1, file2):\n\u001b[0;32m--> 106\u001b[0m     write_json(file2, read_jsonl(file1))\n",
      "File \u001b[0;32m/workspace/project/refact/code/utils.py:89\u001b[0m, in \u001b[0;36mread_jsonl\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_jsonl\u001b[39m(filename):\n\u001b[0;32m---> 89\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fr:\n\u001b[1;32m     90\u001b[0m         data_pool \u001b[38;5;241m=\u001b[39m [json\u001b[38;5;241m.\u001b[39mloads(line) \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m fr\u001b[38;5;241m.\u001b[39mreadlines()]\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data_pool\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './../../exp/triviaqa/infer/llama3_triviaqa_validation_sample_2k_1shot/generate2.json'"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "\n",
    "input_path = \"./../exp/triviaqa/infer/llama3_triviaqa_validation_sample_2k_1shot/generate2.json\"\n",
    "\n",
    "utils.jsonl2json(input_path, input_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/refact/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.47s/it]\n",
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'assistant', 'content': 'The capital of France is Paris.'}\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import torch\n",
    "\n",
    "'''\n",
    "Candidate Models: [\"Meta-Llama-3.1-8B-Instruct\", \"Qwen2-7B-Instruct\", \"Mistral-7B-Instruct-2\"]\n",
    "'''\n",
    "model_id = \"/workspace/model/Qwen2-7B-Instruct\"\n",
    "\n",
    "persona = {\n",
    "    \"pirate\": \"You are a pirate chatbot who always responds in pirate speak!\",\n",
    "    \"liar\": \"You are a liar!\",\n",
    "    \"assistant\": \"You are an assistant chatbot who always responds in a helpful way!\",\n",
    "}\n",
    "user_input = \"What is the capital of France?\" \n",
    "\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": persona[\"liar\"]},\n",
    "    {\"role\": \"user\", \"content\": user_input},\n",
    "]\n",
    "\n",
    "outputs = pipeline(\n",
    "    messages,\n",
    "    max_new_tokens=512,\n",
    ")\n",
    "print(outputs[0][\"generated_text\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
